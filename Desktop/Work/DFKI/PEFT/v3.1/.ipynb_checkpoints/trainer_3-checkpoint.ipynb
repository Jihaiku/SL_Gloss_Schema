{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffb5727-c7e0-4b28-934c-2c187522ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training pipeline for Whisper model with LoRA adaptation...\n",
      "\n",
      "Loading model...\n",
      "binary_path: C:\\Users\\cdhye\\anaconda3\\envs\\ASR\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "Model loaded and LoRA applied.\n",
      "\n",
      "Loading and preparing dataset...\n",
      "Sampling rate: 16000 Hz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436ff9604602454db584087f4180880d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4743 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5276d1e9cd04a02987abd6990079abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 4743\n",
      "Evaluation samples: 81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='444' max='444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [444/444 27:07, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.725260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.711080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Arguments ===\n",
      "output_dir: openai/whisper-tiny-en-0.005-128\n",
      "per_device_train_batch_size: 16\n",
      "gradient_accumulation_steps: 2\n",
      "learning_rate: 0.001\n",
      "warmup_steps: 500\n",
      "num_train_epochs: 3\n",
      "eval_strategy: None\n",
      "per_device_eval_batch_size: 8\n",
      "generation_max_length: 128\n",
      "logging_steps: 25\n",
      "save_total_limit: 3\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import csv\n",
    "import evaluate\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "from config_0 import load_config\n",
    "from dataset_1 import load_and_prepare_dataset, get_prepare_dataset_fn, load_processors\n",
    "from model_2 import load_quantized_whisper_model, apply_lora\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#\n",
    "# Load Configs\n",
    "#\n",
    "config = load_config()\n",
    "\n",
    "model_name_or_path = config[\"model_name_or_path\"]\n",
    "model = config[\"model\"]\n",
    "language = config[\"language\"]\n",
    "language_abbr = config[\"language_abbr\"]\n",
    "task = config[\"task\"]\n",
    "dataset_name = config[\"dataset_name\"]\n",
    "size = config[\"size\"]\n",
    "user_name = config[\"user_name\"]\n",
    "peft_type = config[\"peft_type\"]\n",
    "# lora_config = config.get(\"lora_config\")  # or however it's defined in your code\n",
    "# model_config = config.get(\"model_config\")  # same\n",
    "\n",
    "\n",
    "csv_filename = \"model_results.csv\"\n",
    "rand_num = random.randint(1,200)\n",
    "seed = rand_num\n",
    "output_dir = f\"{model_name_or_path}-{language_abbr}-{size}-{seed}\"\n",
    "\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, features):\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, processor, train_dataset, eval_dataset, output_dir,\n",
    "    seed, csv_filename=\"model_results.csv\"):\n",
    "\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=16,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=1e-3,\n",
    "        warmup_steps=500,\n",
    "        num_train_epochs=3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        per_device_eval_batch_size=8,\n",
    "        generation_max_length=128,\n",
    "        logging_steps=25,\n",
    "        remove_unused_columns=False,\n",
    "        label_names=[\"labels\"],\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    model.config.use_cache = False\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        processing_class=processor.feature_extractor\n",
    "        # processing_class=processor.tokenizer\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\"\n",
    "    trainer.train()\n",
    "\n",
    "    return training_args, trainer\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running training pipeline for Whisper model with LoRA adaptation...\")\n",
    "\n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    base_model = load_quantized_whisper_model()\n",
    "    model = apply_lora(base_model)\n",
    "    print(\"Model loaded and LoRA applied.\\n\")\n",
    "\n",
    "    # Load and prepare dataset\n",
    "    print(\"Loading and preparing dataset...\")\n",
    "    dataset = load_and_prepare_dataset()\n",
    "\n",
    "    # Optional: print sampling rate\n",
    "    sample_audio = dataset[\"train\"][0][\"audio\"]\n",
    "    print(f\"Sampling rate: {sample_audio['sampling_rate']} Hz\")\n",
    "\n",
    "    # Preprocess (no multiprocessing on Windows)\n",
    "    # Load feature extractor, tokenizer, processor\n",
    "    feature_extractor, tokenizer, processor = load_processors(model_name_or_path, language, task)\n",
    "    \n",
    "    # Prepare dataset with correct scope\n",
    "    prepare_dataset = get_prepare_dataset_fn(feature_extractor, tokenizer)\n",
    "    dataset = dataset.map(prepare_dataset, remove_columns=[\"audio\", \"sentence\"])\n",
    "\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"test\"]\n",
    "\n",
    "    print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "    print(f\"Evaluation samples: {len(eval_dataset)}\\n\")\n",
    "\n",
    "   # Train\n",
    "    training_args, trainer  = train_model(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        output_dir=output_dir,\n",
    "        seed=seed,\n",
    "        csv_filename=csv_filename\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Training Arguments ===\")\n",
    "    print(f\"output_dir: {training_args.output_dir}\")\n",
    "    print(f\"per_device_train_batch_size: {training_args.per_device_train_batch_size}\")\n",
    "    print(f\"gradient_accumulation_steps: {training_args.gradient_accumulation_steps}\")\n",
    "    print(f\"learning_rate: {training_args.learning_rate}\")\n",
    "    print(f\"warmup_steps: {training_args.warmup_steps}\")\n",
    "    print(f\"num_train_epochs: {training_args.num_train_epochs}\")\n",
    "    print(f\"eval_strategy: {training_args.evaluation_strategy}\")\n",
    "    print(f\"per_device_eval_batch_size: {training_args.per_device_eval_batch_size}\")\n",
    "    print(f\"generation_max_length: {training_args.generation_max_length}\")\n",
    "    print(f\"logging_steps: {training_args.logging_steps}\")\n",
    "    print(f\"save_total_limit: {training_args.save_total_limit}\")\n",
    "\n",
    "    \n",
    "    print(\"\\nTraining complete.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
